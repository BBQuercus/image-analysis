{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import glob, os, random, re, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import scipy.ndimage as ndi\n",
    "import skimage.filters as flt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.patches import Patch\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.io import imread, imsave\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "from skimage.morphology import remove_small_objects\n",
    "from ipywidgets import interact, widgets\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# FISH colocalization with granules\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "This notebook is part of my master thesis titled: \"Single-molecule imaging of mRNA to study translational regulation\".\n",
    "\n",
    "## Colocalization overview\n",
    "\n",
    "1. [Image import](#section1)\n",
    "2. [DAPI-gated cellular segmentation](#section2)\n",
    "3. [Colocalization analysis](#section3)\n",
    "4. [Spot detection](#section4)\n",
    "5. [Cell-to-cell measurements](#section5)\n",
    "6. [Batch processing](#section6)\n",
    "7. [Data analysis](#section7)\n",
    "8. [(Functions)](#section8)\n",
    "\n",
    "In this experiment, we wanted to determine if a new construct containing standard-MCP-Halo-G3BP1 is able to recruit reporter mRNAs to stress granules with a higher efficacy compared to a construct without G3BP1. Three different mRNAs (pIM52, pIM52-CMV-5'TOP, ATF-4) will be used.\n",
    "\n",
    "As positive control, luminescent beads will be used for 'perfect' colocalization. A singly labeled sample (either granules or FISH) will be used to measure the effect of crosstalk and serves as negative control.\n",
    "\n",
    "The previously constructed pipeline for OptoGranule induction will be used to test wether the FISH (mRNA) and the granule signals colocalize. This pipeline will segment cells based on their DAPI signal and measure colocalization as well as count the number of granules in each cell.\n",
    "\n",
    "Lastly, some of the subsequent code was adapted from the European Molecular Biology Laboratory, Jonas Hartmann, Karin Sasaki, Toby Hodges (© 2018, for cellular segmentation) and from Justin Bois, California Institute of Technology (© 2015, for colocalization). Everything is distributed under a MIT license."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<a id='section1'></a>\n",
    "# 1. Image import\n",
    "\n",
    "First, the images are imported as numpy array. The filetype (here: .stk) must be specified in order to import the correct images. Once imported, the images are displayed for visual inspection. The channels should be labeled as indicated below.\n",
    "\n",
    "- Image 0 – Nuclear label (eg. DAPI) – here: DAPI, 405 nm\n",
    "- Image 1 – Colocalization 1 (eg. Halo or IF) – here: OptoG-mRuby, 561 nm\n",
    "- Image 2 – Colocalization 2 (eg. FISH) – here: FISH-Renilla, 640 nm\n",
    "\n",
    "The subsequent sharp function is used to determine the sharpest slice of the z-stack images. This is done by measuring the average intensity differences between pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def sharp(img):\n",
    "    '''\n",
    "    Returns index of the sharpest slice in an image array of shape z, x, y.\n",
    "    '''\n",
    "    sharpness = []\n",
    "    array = np.asarray(img, dtype=np.int32)\n",
    "    for i in range(array.shape[0]):\n",
    "        y, x = np.gradient(array[i])\n",
    "        norm = np.sqrt(x**2 + y**2)\n",
    "        sharpness.append(np.average(norm))\n",
    "    return sharpness.index(max(sharpness))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# File path\n",
    "index = 'example'\n",
    "root = 'colocalization_example/'\n",
    "outfolder = 'colocalization_example/'\n",
    "lambdas = [405, 561, 640]\n",
    "\n",
    "# Listing all files with index and .stk extension\n",
    "files = glob.glob('{}{}*.stk'.format(root, index))\n",
    "\n",
    "# Find sharpest image in img0_lambda channel\n",
    "for f in files:\n",
    "    if str(lambdas[0]) in f:\n",
    "        img_sharp = sharp(imread(f))\n",
    "\n",
    "# Open all images corresponding to a lambda\n",
    "for f in files:\n",
    "    for i in range(len(lambdas)):\n",
    "        if str(lambdas[i]) in f:\n",
    "            globals()['img_'+str(lambdas[i])] = imread(f)[img_sharp]\n",
    "\n",
    "# Stack and convert to uint16\n",
    "img = np.stack([globals()['img_'+str(lambdas[i])] for i in range(len(lambdas))], axis=0)\n",
    "\n",
    "# Check if images are loaded correctly\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 10))\n",
    "ax[0].set_title('DAPI channel')\n",
    "ax[0].imshow(img[0], interpolation=None, cmap='gray')\n",
    "ax[1].set_title('Colocalization channel 1')\n",
    "ax[1].imshow(img[1], interpolation=None, cmap='gray')\n",
    "ax[2].set_title('Colocalization channel 2')\n",
    "ax[2].imshow(img[2], interpolation=None, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## 2. DAPI-gated cellular segmentation\n",
    "\n",
    "To do a cellular analysis, all cells are segmented. The parts of this multi-step process are described below.\n",
    "\n",
    "**Preprocessing** – To obtain a better segmentation later on, the image acquired through the DAPI channel will be smoothed by a gauss filer. Different sigmas (below) can be used to change 'smoothing intensity'.\n",
    "\n",
    "**Thresholding** – A global threshold will be applied to remove background noise and to be left with the DAPI nuclei. A variety of thresholding options can be selected. Currently 'otsu' is used.\n",
    "\n",
    "**Connected component labeling** – As some DAPI nuclei currently show up to be combined, a further smoothing and a exact euclidean distance transform is used to separate these combined nuclei. Thereby, undersegmentation artifacts can be minimized.\n",
    "\n",
    "**Seeding** – Local maxima are used to detect every DAPI nucleus. This provides a seed for the later segmentation.\n",
    "\n",
    "**Watershed** – Segmentation using the generated seeds. Inverted watershed or random walker can be used (change name). Cells on the border might slightly skew with the results, but because a 63x objective is required to visualize the FISH spots, removing these cells would result in only very few (if any) cells remaining per image. Furthermore colocalization is analyzed and not total spot count.\n",
    "\n",
    "**Nuclei** – Dilate nuclei (more space around nuclei) and substract these from the watershed segmentation. Therefore, one is left with only the cytoplasms and the image background.\n",
    "\n",
    "**Background** – A threshold based approach in the first colocalization channel to remove background. As the removal on a cellular basis and would mess up labelling, the background is shown as whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(dil=0):\n",
    "    '''\n",
    "    Given a int, creates a 'dilation' of that size.\n",
    "    '''\n",
    "    a = []\n",
    "    b = []\n",
    "    for i in range(dil):\n",
    "        a.append(['F'*(dil-i)+'T'*(i+1)+'T'*(i)+'F'*(dil-i)])\n",
    "    a.append(('T'*(dil*2+1)).split())\n",
    "    for i in range(dil-1, -1, -1):\n",
    "        a.append(['F'*(dil-i)+'T'*(i+1)+'T'*(i)+'F'*(dil-i)])\n",
    "    for i in a:\n",
    "        for j in i:\n",
    "            b.append(list(j))\n",
    "    for n,i in enumerate(b): \n",
    "        for m,j in enumerate(i): \n",
    "            if j == 'F': \n",
    "                b[n][m] = False \n",
    "            if j == 'T': \n",
    "                b[n][m] = True \n",
    "    return np.array(b, dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Parameters for cellular segmentation\n",
    "img0_sigma = 3\n",
    "img0_min_size = 200\n",
    "img0_min_distance = 50\n",
    "img0_dilation = 5\n",
    "img0_thresh_bg = 1000\n",
    "img0_min_size_bg = 10_000\n",
    "\n",
    "# Gauss-smoothening\n",
    "img0_smooth = ndi.filters.gaussian_filter(img[0], img0_sigma)\n",
    "\n",
    "# Thresholding and removal of small objects\n",
    "img0_thresh = flt.threshold_otsu(img0_smooth)\n",
    "img0_smooth_thresh = img0_smooth>img0_thresh\n",
    "img0_mem = remove_small_objects(img0_smooth_thresh, img0_min_size)\n",
    "\n",
    "# Labeling, euclidean distance transform, smoothing\n",
    "img0_cell_labels, _ = ndi.label(img0_mem)\n",
    "img0_dist_trans = ndi.distance_transform_edt(img0_mem)\n",
    "img0_dist_trans_smooth = ndi.filters.gaussian_filter(img0_dist_trans, sigma=img0_sigma)\n",
    "\n",
    "# Seeding (and dilating for visualization)\n",
    "img0_seeds = peak_local_max(img0_dist_trans_smooth, indices=False, min_distance=img0_min_distance)\n",
    "img0_seeds_labeled = ndi.label(img0_seeds)[0]\n",
    "img0_seeds_labeled_dil = ndi.filters.maximum_filter(img0_seeds_labeled, size=10)\n",
    "\n",
    "# Inverted watershed for segmentation\n",
    "img0_seg = watershed(~img0_smooth, img0_seeds_labeled)\n",
    "\n",
    "# Removal of dilated nuclei\n",
    "img0_seg_nuclei = img0_seg * ~convolve2d(img0_mem.astype(int), dilate(img0_dilation).astype(int), mode='same').astype(bool)\n",
    "\n",
    "# Removal of background based on colocalization channel 1\n",
    "img0_thresh_bg = flt.threshold_triangle(img[1])\n",
    "img0_smooth_thresh_bg = img[1]>img0_thresh_bg\n",
    "img0_seg_clean = img0_seg_nuclei * img0_smooth_thresh_bg\n",
    "\n",
    "# Removal of 'debris'\n",
    "img0_seg_labeled, img0_seg_labels = ndi.measurements.label(img0_seg_clean)\n",
    "img0_seg_label_size = [(img0_seg_labeled == label).sum() for label in range(img0_seg_labels + 1)]\n",
    "for label, size in enumerate(img0_seg_label_size):\n",
    "    if size < img0_min_size_bg:\n",
    "        img0_seg_clean[img0_seg_labeled == label] = 0\n",
    "\n",
    "# Visualization\n",
    "fig, ax = plt.subplots(4, 2, figsize=(10, 20))\n",
    "ax[0,0].set_title('Raw image')\n",
    "ax[0,0].imshow(img[0], interpolation='none', cmap='gray')\n",
    "ax[0,1].set_title('Smoothed image')\n",
    "ax[0,1].imshow(img0_smooth, interpolation='none', cmap='gray')\n",
    "ax[1,0].set_title('Thresholded DAPI')\n",
    "ax[1,0].imshow(img0_mem, interpolation='none', cmap='gray')\n",
    "ax[1,1].set_title('Smoothed labels')\n",
    "ax[1,1].imshow(img0_dist_trans_smooth, interpolation='none', cmap='viridis')\n",
    "ax[2,0].set_title('Unique seeds')\n",
    "ax[2,0].imshow(img0_dist_trans_smooth, interpolation='none', cmap='viridis')\n",
    "ax[2,0].imshow(img0_smooth, interpolation='none', cmap='gray')\n",
    "ax[2,0].imshow(np.ma.array(img0_seeds_labeled_dil, mask=img0_seeds_labeled_dil==0), interpolation='none', cmap='prism')\n",
    "ax[2,1].set_title('Segmented cells')\n",
    "ax[2,1].imshow(img0_smooth, interpolation='none', cmap='gray')\n",
    "ax[2,1].imshow(np.ma.array(img0_seg, mask=img0_seg==0), interpolation='none', cmap='prism', alpha=0.4)\n",
    "ax[3,0].set_title('Removed nuclei')\n",
    "ax[3,0].imshow(img0_smooth, interpolation='none', cmap='gray')\n",
    "ax[3,0].imshow(np.ma.array(img0_seg_nuclei, mask=img0_seg_nuclei==0), interpolation='none', cmap='prism', alpha=0.4)\n",
    "ax[3,1].set_title('Removed background and debris')\n",
    "ax[3,1].imshow(img0_smooth, interpolation='none', cmap='gray')\n",
    "ax[3,1].imshow(np.ma.array(img0_seg_clean, mask=img0_seg_clean==0), interpolation='none', cmap='prism', alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "## 3. Colocalization analysis\n",
    "\n",
    "The pearson correlation coefficient (PCC) can be used to quantify colocalization with a intensity weight. The equation is shown below.\n",
    "\n",
    "\\begin{align}\n",
    "r = \\frac{\\sum_i\\left(I_{1,i} - \\bar{I}_1\\right)\\left(I_{2,i} - \\bar{I}_2\\right)}{\\sqrt{\\left(\\sum_i \\left(I_{1,i} - \\bar{I}_1\\right)^2\\right)\\left(\\sum_i \\left(I_{2,i} - \\bar{I}_2\\right)^2\\right)}}.\n",
    "\\end{align}\n",
    "\n",
    "The image set is tested for statistical relevance i.e. if the colocalization is greater than simple variance. This is done via scrambling small blocks of the image. The blocks' height and width are equal to the point spread function (PSF). The PCC is then calculated on the scrambled image blocks. The PSF can be approximated using the rayleigh criterion as follows.\n",
    "\n",
    "\\begin{align}\n",
    "R_{\\text{Widefield}} = \\frac{0.6 \\times \\lambda}{\\text{NA}} \\quad R_{\\text{Confocal}} = \\frac{0.4 \\times \\lambda}{\\text{NA}}\n",
    "\\end{align}\n",
    "\n",
    "The edges are mirrored to obtain blocks that are multiples of the PSF. The widget below can be used to compare the effects of scrambling and background substraction on colocalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mirror_edges(img, psf_width):\n",
    "    '''\n",
    "    Given a 2D image, boundaries are padded by mirroring so that\n",
    "    the dimensions of the image are multiples for the width of the\n",
    "    point spread function.\n",
    "    '''\n",
    "    # Required padding\n",
    "    pad_i = psf_width - (img.shape[0] % psf_width)\n",
    "    pad_j = psf_width - (img.shape[1] % psf_width)\n",
    "    \n",
    "    # Width of padding\n",
    "    pad_top = pad_i // 2\n",
    "    pad_bot = pad_i - pad_top\n",
    "    pad_left = pad_j // 2\n",
    "    pad_right = pad_j = pad_left\n",
    "    \n",
    "    # Numpy padding\n",
    "    return np.pad(img, ((pad_top, pad_bot), (pad_left, pad_right)), mode='reflect')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_blocks(img, width, roi=None, roi_method='all'):\n",
    "    '''\n",
    "    Converts image to list of square subimages called 'blocks'.\n",
    "    '''\n",
    "    # ROI initialization\n",
    "    if roi is None:\n",
    "        roi = np.ones_like(img)\n",
    "    \n",
    "    # Method for determining if in ROI or not\n",
    "    if roi_method == 'all':\n",
    "        roi_test = np.all\n",
    "    else:\n",
    "        roi_test = np.any\n",
    "        \n",
    "    # Construction of block list\n",
    "    return np.array([img[i:i + width, j:j + width]\n",
    "                        for i in range(0, img.shape[0], width)\n",
    "                            for j in range(0, img.shape[1], width)\n",
    "                                if roi_test(roi[i:i + width, j:j + width])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scramble(blocks_1, blocks_2_flat, scrambles):\n",
    "    '''\n",
    "    Scrambles blocks_1 n_scramble times and returns the Pearson r values.\n",
    "    '''\n",
    "    r_scr = np.zeros(scrambles)\n",
    "    for i in range(scrambles):\n",
    "        random.shuffle(blocks_1)\n",
    "        r, _ = st.pearsonr(np.array(blocks_1).ravel(), blocks_2_flat)\n",
    "        r_scr[i] = r\n",
    "    r_scr = [i for i in r_scr if ~np.isnan(i)]\n",
    "    return r_scr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_coloc(img1, img2, psf=100, scrambles=200):\n",
    "    # Mirror edges\n",
    "    img1_mirror = mirror_edges(img1, psf)\n",
    "    img2_mirror = mirror_edges(img2, psf)\n",
    "\n",
    "    # Generate blocks of both channels\n",
    "    img1_blocks = img_to_blocks(img1_mirror, psf)\n",
    "    img2_blocks = img_to_blocks(img2_mirror, psf)\n",
    "\n",
    "    # Store blocks of channel 2 as flattened array (not scrambled)\n",
    "    img2_blocks_flat = np.array(img2_blocks).flatten()\n",
    "\n",
    "    # Unscrambled and scrambled R value(s)\n",
    "    img1_unscr, p = st.pearsonr(np.array(img1_blocks).ravel(), img2_blocks_flat)\n",
    "    img1_scr = scramble(img1_blocks, img2_blocks_flat, scrambles)\n",
    "    \n",
    "    # Visualization\n",
    "    _ = sns.distplot(img1_scr, bins=int(np.sqrt(scrambles)))\n",
    "    plt.plot([img1_unscr, img1_unscr], plt.gca().get_ylim(), '-')\n",
    "    plt.title('Scrambled histogram vs. \"real\" image')\n",
    "    plt.xlabel('Pearsons r-value')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(t_lambda = widgets.ToggleButtons(options=[488, 561, 640], value=640, description='Wavelength: '),\n",
    "         t_na = widgets.ToggleButtons(options=[0.7, 1.4, 1.45], value=1.45, description='NA: '),\n",
    "         t_bg = widgets.ToggleButtons(options=[True, False], description='Segmented: '),\n",
    "         t_scrambles = widgets.IntSlider(min=0, max=2000, step=100, value=200, description='Scrambles: '))\n",
    "def g(t_lambda, t_na, t_bg, t_scrambles):\n",
    "    img1 = img[1] * img0_seg_clean\n",
    "    img2 = img[2] * img0_seg_clean\n",
    "    if t_bg == False:\n",
    "        img1 = img[1]\n",
    "        img2 = img[2]\n",
    "    t_psf = int((0.4 * t_lambda) / t_na)\n",
    "    test_coloc(img1, img2, t_psf, t_scrambles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## 4. Spot detection\n",
    "\n",
    "To find optimal spot detection parameters in the second image channel, the widgets below can be used. In this pipeline, the spot detection is used filter out false positives. Cells, for example, which don't have any spots but seem to have significant colocalization values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_spot_counter(image, sigma, block_size, thresh_abs, min_distance):\n",
    "    # Set thresholds to reduce noise\n",
    "    test_smooth = ndi.filters.gaussian_filter(image, sigma)\n",
    "    thresh = flt.threshold_local(test_smooth, block_size, offset=0) \n",
    "    \n",
    "    # Find and label seeds\n",
    "    seeds = peak_local_max(thresh, indices=False, min_distance=min_distance, threshold_abs=thresh_abs)\n",
    "    seeds_labeled = ndi.label(seeds)[0]\n",
    "    seeds_labeled_dil = ndi.filters.maximum_filter(seeds_labeled, size=5) # Dilates seeds – more visible\n",
    "    seeds_masked_labeled = np.ma.array(seeds_labeled_dil, mask=seeds_labeled_dil==0)\n",
    "    seeds_unique = len(np.unique(seeds_labeled_dil)[1:])\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.title('Detected spots')\n",
    "    plt.imshow(image, interpolation='none', cmap='gray')\n",
    "    plt.imshow(seeds_masked_labeled, interpolation='none', cmap='prism', alpha=0.5)\n",
    "    print('Unique spots:', seeds_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "@interact(t_img = widgets.ToggleButtons(options=['1', '2'], description='Channel: '),\n",
    "         t_sigma = widgets.IntSlider(min=0, max=20, step=1, value=1, description='Sigma: '),\n",
    "         t_block_size = widgets.IntSlider(min=1, max=21, step=2, value=5, description='Block size: '),\n",
    "         t_thresh_abs = widgets.IntSlider(min=0, max=15_000, step=100, value=7_000, description='Treshold: '),\n",
    "         t_min_distance = widgets.IntSlider(min=0, max=30, step=1, value=5, description='Min. dist.: '))\n",
    "def g(t_img, t_sigma, t_block_size, t_thresh_abs, t_min_distance):\n",
    "    t_img_ = img[int(t_img)]\n",
    "    test_spot_counter(t_img_, t_sigma, t_block_size, t_thresh_abs, t_min_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## 5. Cell-to-cell measurements\n",
    "\n",
    "The colocalization and spot detection functions will be used to record their respective output on a cellular basis. In order to track the settings used for the analysis, all parameters are saved together with the measurements. Prior to the measurements, the background will be substracted as represented above ([DAPI-gated cellular segmentation](#section2)). All values are combined and stored in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters for spot detection and colocalization\n",
    "img1 = img[1]\n",
    "img1_sigma = 1\n",
    "img1_block_size = 5\n",
    "img1_min_distance = 0\n",
    "img1_thresh = 5000\n",
    "\n",
    "img2 = img[2]\n",
    "img2_sigma = 1\n",
    "img2_block_size = 5\n",
    "img2_min_distance = 0\n",
    "img2_thresh = 5000\n",
    "\n",
    "psf_lambda = 648\n",
    "psf_na = 1.45\n",
    "psf = int((0.6 * img1_lambda) / img1_na)\n",
    "scrambles = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = {'filename'                 : [],\n",
    "           'cell_ID'                  : [],\n",
    "           \n",
    "           # Measurements\n",
    "           'cell_area'                : [],\n",
    "           'img1_cell_intensity_mean' : [],\n",
    "           'img1_cell_intensity_std'  : [],\n",
    "           'img1_spot_count'          : [],\n",
    "           'img2_cell_intensity_mean' : [],\n",
    "           'img2_cell_intensity_std'  : [],\n",
    "           'img2_spot_count'          : [],\n",
    "           'img1_2_coloc_org'         : [],\n",
    "           'img1_2_coloc_scr'         : [],\n",
    "           \n",
    "           # Parameters\n",
    "           'psf'                      : [],\n",
    "           'scrambles'                : [],\n",
    "           'img0_sigma'               : [],\n",
    "           'img0_min_size'            : [],\n",
    "           'img0_min_distance'        : [],\n",
    "           'img0_dilation'            : [],\n",
    "           'img0_thresh_bg'           : [],\n",
    "           'img0_min_size_bg'         : [],\n",
    "           'img1_sigma'               : [],\n",
    "           'img1_block_size'          : [],\n",
    "           'img1_min_distance'        : [],\n",
    "           'img1_thresh'              : [],\n",
    "           'img2_sigma'               : [],\n",
    "           'img2_block_size'          : [],\n",
    "           'img2_min_distance'        : [],\n",
    "           'img2_thresh'              : []}\n",
    "           \n",
    "# Smoothing for spot detection\n",
    "img1_smooth = ndi.filters.gaussian_filter(img1, img1_sigma)\n",
    "img2_smooth = ndi.filters.gaussian_filter(img2, img2_sigma)\n",
    "\n",
    "for cell_ID in np.unique(img0_seg_clean)[1:]:\n",
    "    img0_cell_mask = (img0_seg_clean==cell_ID) * img0_smooth_bg\n",
    "    \n",
    "    # Area measurement on cell mask\n",
    "    cell_area = np.count_nonzero(img0_cell_mask)\n",
    "    \n",
    "    # Intensity and spot count measurements\n",
    "    img1_cell = np.where(np.ma.array(img0_cell_mask, mask=img0_cell_mask==0), img1_smooth, 0)\n",
    "    img1_cell_intensity_mean = np.mean(np.nonzero(img1_cell))\n",
    "    img1_cell_intensity_std = np.std(np.nonzero(img1_cell))\n",
    "    img1_spot_count = spot_counter(img1_cell, img1_block_size, img1_thresh, img1_min_distance)\n",
    "    img2_cell = np.where(np.ma.array(img0_cell_mask, mask=img0_cell_mask==0), img2_smooth, 0)\n",
    "    img2_cell_intensity_mean = np.mean(np.nonzero(img2_cell))\n",
    "    img2_cell_intensity_std = np.std(np.nonzero(img2_cell))\n",
    "    img2_spot_count = spot_counter(img2_cell, img2_block_size, img2_thresh, img2_min_distance)\n",
    "    \n",
    "    # Colocalization measurements       \n",
    "    img1_2_coloc_org, img1_2_coloc_scr = coloc((img1*img0_cell_mask), (img2*img0_cell_mask), psf, scrambles)\n",
    "        \n",
    "    results['filename'].append(os.path.basename(os.path.normpath(root)))\n",
    "    results['cell_ID'].append(cell_ID)\n",
    "    \n",
    "    # Measurements\n",
    "    results['cell_area'].append(cell_area)\n",
    "    results['img1_cell_intensity_mean'].append(img1_cell_intensity_mean)\n",
    "    results['img1_cell_intensity_std'].append(img1_cell_intensity_std)\n",
    "    results['img1_spot_count'].append(img1_spot_count)\n",
    "    results['img2_cell_intensity_mean'].append(img2_cell_intensity_mean)\n",
    "    results['img2_cell_intensity_std'].append(img2_cell_intensity_std)\n",
    "    results['img2_spot_count'].append(img2_spot_count)\n",
    "    results['img1_2_coloc_org'].append(img1_2_coloc_org)\n",
    "    results['img1_2_coloc_scr'].append(img1_2_coloc_scr)\n",
    "    \n",
    "    # Parameters\n",
    "    results['psf'].append(psf)\n",
    "    results['scrambles'].append(scrambles)\n",
    "    results['img0_sigma']append(img0_sigma)\n",
    "    results['img0_min_size'].append(img0_min_size)\n",
    "    results['img0_dilation'].append(img0_dilation)\n",
    "    results['img0_thresh_bg'].append(img0_thresh_bg)\n",
    "    results['img0_min_size_bg'].append(img0_min_size_bg)\n",
    "    results['img1_sigma'].append(img1_sigma)\n",
    "    results['img1_block_size'].append(img1_block_size)\n",
    "    results['img1_min_distance'].append(img1_min_distance)\n",
    "    results['img1_thresh'].append(img1_thresh)\n",
    "    results['img2_sigma'].append(img2_sigma)\n",
    "    results['img2_block_size'].append(img2_block_size)\n",
    "    results['img2_min_distance'].append(img2_min_distance)\n",
    "    results['img2_thresh'].append(img2_thresh)\n",
    "\n",
    "# Export results\n",
    "with open(''.join([filename, '.csv']),'w') as outfile:\n",
    "    header_string = '\\t'.join(results.keys()) + '\\n'\n",
    "    outfile.write(header_string)\n",
    "    for index in range(len(results['filename'])):\n",
    "        data_string = '\\t'.join([str(results[key][index]) for key in results.keys()]) + '\\n'\n",
    "        outfile.write(data_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>\n",
    "## 6. Batch processing\n",
    "\n",
    "Batch processing means running complete pipeline over multiple images. The run_pipeline function is located in the file colocalization.py together with all dependencies and helper functions. The documentation is as follows.\n",
    "\n",
    "```python\n",
    "def run_pipeline(index, root, outfolder):\n",
    "'''\n",
    "Runs a colocalization and spot detection pipeline.\n",
    "Parameters\n",
    "----------\n",
    "index: str\n",
    "    Base name / index for one set of image files.\n",
    "root: dir\n",
    "    Directory where image files are located.\n",
    "outfolder: dir\n",
    "    Directory for output.\n",
    "Returns\n",
    "----------\n",
    "outfolder/index.csv: .csv file\n",
    "    File with all values in the outfolder.\n",
    "'''\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from colocalization import run_pipeline\n",
    "\n",
    "# File path\n",
    "root = 'colocalization_example/'\n",
    "outfolder = 'colocalization_example/'\n",
    "\n",
    "# Indices based on the .nd files\n",
    "indices = [file.split('.')[0] for file in os.listdir(root) if file.endswith('.nd')]\n",
    "\n",
    "# Batch processing\n",
    "for i in indices:\n",
    "    files = glob.glob('{}{}*.stk'.format(root, i))\n",
    "    run_pipeline(files, root, outfolder)\n",
    "    print(f'{indices.index(i) + 1}/{len(indices)} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "## 7. EDA and visualization\n",
    "\n",
    "Once all images have been processed, they are imported as pandas dataframe. After some data cleaning, a suitable form of visualization is used to pinpoint the key features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section8'></a>\n",
    "## 8. Functions\n",
    "\n",
    "Complete functions used in the final pipeline. The test_functions have less documentation and include some visualization. Furthermore, for the full documentation on all functions above, check the colocalization.py file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coloc(img1, img2, psf=3, scrambles=1000):\n",
    "    '''\n",
    "    Colocalization of two images and comparison with scrambles.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img1: nd.array\n",
    "        Image array of to be scrambled image.\n",
    "    img2: nd.array\n",
    "        Image array of the 'static' image.\n",
    "    psf: int, default 3\n",
    "        Point spread function of the longer wavelength.\n",
    "    scrambles: int, default 1000\n",
    "        Number of scrambles to calculate r value of.\n",
    "    Returns\n",
    "    ----------\n",
    "    outputs: float, list of floats\n",
    "        R values (unscrambled (float) and scrambled(list of floats))\n",
    "    '''\n",
    "    # Mirror edges\n",
    "    img1_mirror = mirror_edges(img1, psf)\n",
    "    img2_mirror = mirror_edges(img2, psf)\n",
    "\n",
    "    # Generate blocks of both channels\n",
    "    img1_blocks = img_to_blocks(img1_mirror, psf)\n",
    "    img2_blocks = img_to_blocks(img2_mirror, psf)\n",
    "\n",
    "    # Store blocks of channel 2 as flattened array (not scrambled)\n",
    "    img2_blocks_flat = np.array(img2_blocks).flatten()\n",
    "\n",
    "    # Scamblin' and obtain R value\n",
    "    img1_scr = scramble(img1_blocks, img2_blocks_flat, scrambles)\n",
    "    \n",
    "    # Unscrambled R value\n",
    "    img1_unscr, p = st.pearsonr(np.array(img1_blocks).ravel(), img2_blocks_flat)\n",
    "    \n",
    "    return img1_unscr, img_src;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_counter(img_, block_size=1, threshold=0, min_distance=0):\n",
    "    '''\n",
    "    Counts spots returning the number of unique spots in a given area.\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_: np.array.shape(x, x)\n",
    "        Image on which spots should be counted.\n",
    "    block_size: int, default 0\n",
    "        Odd size of pixel neighborhood to perform a local threshold.\n",
    "    threshold: int, default 0\n",
    "        Local maximum threshold filtering out any lower values.\n",
    "    min_distance: int, default 0\n",
    "        Minimum distance between two potential spots.\n",
    "    Returns\n",
    "    ----------\n",
    "    output: int\n",
    "        Unique seed count.\n",
    "    '''\n",
    "    thresh = flt.threshold_local(img_, block_size, offset=5) \n",
    "    seeds = peak_local_max(thresh, indices=False, min_distance=min_distance)\n",
    "    seeds_labeled = ndi.label(seeds)[0]\n",
    "    seeds_unique = len(np.unique(seeds_labeled)[1:]) # '0' to not include background\n",
    "    return seeds_unique"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
